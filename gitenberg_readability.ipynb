{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Python 2 and 3: alternative 4\n",
    "try:\n",
    "    from urllib.parse import urlparse, urlencode\n",
    "    from urllib.request import urlopen, Request\n",
    "    from urllib.error import HTTPError\n",
    "except ImportError:\n",
    "    from urlparse import urlparse\n",
    "    from urllib import urlencode\n",
    "    from urllib2 import urlopen, Request, HTTPError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test existence of file of form:\n",
    "https://raw.githubusercontent.com/GITenberg/---------------------------------------------------------------------------------------------__31854/master/31854-0.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def parse_g_url(url):\n",
    "    name_id = urlparse(url).path.split(\"/\")[-1]\n",
    "    # split on last \"_\" -- seems it's possible to have \n",
    "    return re.search(r'(.*)_(\\d+)$', name_id).groups()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "repo_name_id = map(\n",
    "   parse_g_url,\n",
    "   g_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from itertools import izip, islice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gitenberg_text_url(name, id_, suffix=None):\n",
    "    if suffix:\n",
    "        return \"https://raw.githubusercontent.com/GITenberg/{name}_{id_}/master/{id_}-{suffix}.txt\".format(name=name,\n",
    "                                                                                             id_=id_,\n",
    "                                                                                             suffix=suffix)\n",
    "    else:\n",
    "        return \"https://raw.githubusercontent.com/GITenberg/{name}_{id_}/master/{id_}.txt\".format(name=name,\n",
    "                                                                                             id_=id_)\n",
    "    \n",
    "def text_url_search(name,id_):\n",
    "    suffix_to_try = (None, '0', '8')\n",
    "    \n",
    "    for suffix in suffix_to_try:\n",
    "        url = gitenberg_text_url(name,id_, suffix)\n",
    "        r = requests.head(url)\n",
    "        if r.status_code == 200:\n",
    "            return (True, url)\n",
    "    \n",
    "    return (False, None)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for (url,(name,id_)) in islice(izip(g_files, repo_name_id),10):\n",
    "    (txt_found, txt_url) = text_url_search(name,id_)\n",
    "    print (url, txt_found, txt_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "r = requests.head(txt_url)\n",
    "r.status_code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cert warnings\n",
    "\n",
    "https://urllib3.readthedocs.org/en/latest/security.html#using-certifi-with-urllib3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import urllib3\n",
    "import certifi\n",
    "\n",
    "http = urllib3.PoolManager(\n",
    "    cert_reqs='CERT_REQUIRED', # Force certificate check.\n",
    "    ca_certs=certifi.where(),  # Path to the Certifi bundle.\n",
    ")\n",
    "\n",
    "# You're ready to make verified HTTPS requests.\n",
    "try:\n",
    "    r = http.request('GET', 'https://example.com/')\n",
    "except urllib3.exceptions.SSLError as e:\n",
    "    # Handle incorrect certificate error.\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# https://github.com/kennethreitz/requests/issues/2214#issuecomment-72941896\n",
    "\n",
    "from requests.packages.urllib3.exceptions import InsecureRequestWarning\n",
    "\n",
    "requests.packages.urllib3.disable_warnings(InsecureRequestWarning)\n",
    "\n",
    "import urllib3\n",
    "urllib3.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Readabiliity\n",
    "\n",
    "[readability 0.1 : Python Package Index](https://pypi.python.org/pypi/readability/0.1)\n",
    "\n",
    "```\n",
    "pip install https://github.com/andreasvc/readability/tarball/master\n",
    "pip install Gutenberg\n",
    "```\n",
    "\n",
    "https://github.com/c-w/Gutenberg/blob/master/gutenberg/cleanup/strip_headers.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import readability\n",
    "import requests\n",
    "from gutenberg import cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Moby Dick\n",
    "\n",
    "url = \"https://github.com/GITenberg/Moby-Dick--Or-The-Whale_2701/raw/master/2701.txt\"\n",
    "text = cleanup.strip_headers(requests.get(url).text)\n",
    "text[:100], text[-100:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "readability.getmeasures(text, lang='en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "moby_blob = TextBlob(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read in from data file\n",
    "\n",
    "import pandas as pd\n",
    "from pandas import DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"GITenberg_repos_list_2.tsv\", sep=\"\\t\", encoding=\"UTF-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# what about those multiple txt\n",
    "df.text_files = df.text_files.map(lambda s: [f.strip() for f in s[1:-1].split(\",\") if len(f) and not f.isspace()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def has_standard_txt(g_id, files):\n",
    "    if \"{0}.txt\".format(g_id) in files:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def classify_text_files(g_id, files):\n",
    "    \"\"\"\n",
    "    put into buckets: .txt, -0.txt, -5.txt, -8.txt, other\n",
    "    \"\"\"\n",
    "    \n",
    "    # https://www.gutenberg.org/files/\n",
    "    bucket_labels = [('ascii', \"{g_id}.txt\"),\n",
    "                     ('utf-8', \"{g_id}-0.txt\"),\n",
    "                     ('8-bit', \"{g_id}-8.txt\"), # iso-8859-1, windows-1252, MacRoman, ...\n",
    "                     ('big5',  \"{g_id}-5.txt\")\n",
    "                    ]\n",
    "    \n",
    "    buckets = defaultdict(list) # make values list to be consistent\n",
    "    files_set = set(files)\n",
    "    \n",
    "    for (label, template) in bucket_labels:\n",
    "        f_name = template.format(g_id=g_id)\n",
    "        if f_name in files_set:\n",
    "            buckets[label].append(f_name)\n",
    "            files_set.remove(f_name)\n",
    "            \n",
    "    # pick up rest      \n",
    "    if files_set:\n",
    "        buckets['other'] = list(files_set)\n",
    "    \n",
    "    #print (dict(buckets)  )\n",
    "    return buckets.items()  \n",
    "    \n",
    "# https://raw.githubusercontent.com/GITenberg/Little-Dorrit_963/master/963.txt\n",
    "\n",
    "def gitenberg_url(title, text_file):\n",
    "    return \"https://raw.githubusercontent.com/GITenberg/{title}/master/{text_file}\".format(title=title,\n",
    "                                                                                          text_file=text_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['files_by_encoding'] = df.apply(lambda r:classify_text_files(r.gitb_id, r.text_files), axis=1).map(dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.files_by_encoding.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# study 'other'\n",
    "df['other'] = df.files_by_encoding.map(lambda d: d.get('other'))\n",
    "df.other.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# any other in the form of (\\d+)-(\\d).txt or \\(d+).txt?\n",
    "\n",
    "def unexpected_other(files):\n",
    "    \"\"\"files whose file namelooks suspicious \"\"\"\n",
    "    import re\n",
    "\n",
    "    if files is None:\n",
    "        return False\n",
    "    \n",
    "    for f in files:\n",
    "        if re.search(r'^(\\d+)-(\\d).txt$', f) or re.search(r'^(\\d+).txt$', f):\n",
    "            return True\n",
    "    \n",
    "    return False\n",
    "\n",
    "# hmmm...these files deserve a closer look\n",
    "df[df.other.map(unexpected_other)][['gitb_id','other','text_files']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# compute URL for a text file\n",
    "\n",
    "def gitenberg_raw_url(repo_name, file_name, branch='master'):\n",
    "    if file_name is not None:\n",
    "        return \"https://raw.githubusercontent.com/GITenberg/{repo_name}/{branch}/{file_name}\".format(repo_name=repo_name,\n",
    "                                                                                                file_name=file_name,\n",
    "                                                                                                branch=branch)\n",
    "    else:\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for a given repository, return URL for \"best\" file to work with\n",
    "#preference:  utf-8, ascii, big5, 8-bit (because of ambiguity)\n",
    "# if unicode available, return it and encoding\n",
    "\n",
    "def preferred_file(files_d):\n",
    "    PREF_ORDER = ['utf-8', 'ascii', 'big5', '8-bit']\n",
    "    for f_type in PREF_ORDER:\n",
    "        files_of_type = files_d.get(f_type)\n",
    "        if files_of_type:\n",
    "            return (files_of_type[0], f_type)\n",
    "        \n",
    "    return (None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['preferred_file'] = df.files_by_encoding.map(preferred_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['preferred_text_url'] = df.apply(lambda row: gitenberg_raw_url(row.gitb_name, row.preferred_file[0]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# HTTP HEAD on the file\n",
    "def http_head_status(url):\n",
    "    import requests\n",
    "    \n",
    "    if url is not None:\n",
    "        r = requests.head(url)\n",
    "        return r.status_code\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[:100].preferred_text_url.map(http_head_status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "head_status = _"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "df[:100][head_status == 404][['preferred_text_url']].to_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# decorator that returns a tuple with args and return value\n",
    "\n",
    "def also_arg(func):\n",
    "    \"\"\"\n",
    "    for use for single-argument function\n",
    "    \"\"\"\n",
    "    def wrapper(arg):\n",
    "        try:\n",
    "            result = func(arg)\n",
    "        except Exception, e:\n",
    "            result = e\n",
    "            \n",
    "        return (arg, result)\n",
    "    \n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# http://chriskiehl.com/article/parallelism-in-one-line/\n",
    "from __future__ import print_function\n",
    "from multiprocessing import Pool as ProcessPool\n",
    "from multiprocessing.dummy import Pool as ThreadPool \n",
    "from functools import partial\n",
    "from itertools import islice\n",
    "\n",
    "from math import factorial\n",
    "\n",
    "# http://stackoverflow.com/questions/2348317/how-to-write-a-pager-for-python-iterators/2350904#2350904        \n",
    "def grouper(iterable, page_size):\n",
    "    page= []\n",
    "    for item in iterable:\n",
    "        page.append( item )\n",
    "        if len(page) == page_size:\n",
    "            yield page\n",
    "            page= []\n",
    "    if len(page) > 0:\n",
    "        yield page\n",
    "\n",
    "\n",
    "#get_key_sizes_for_bucket = partial(get_key_sizes, bucket_name=\"aws-publicdatasets\")\n",
    "\n",
    "PAGE_SIZE = 10\n",
    "POOL_SIZE = 8\n",
    "MAX_SEGMENTS = 5 # replace with None for all segments\n",
    "CHUNK_SIZE = 10\n",
    "\n",
    "pool = ThreadPool(POOL_SIZE)  # or ThreadPool\n",
    "results_iter = pool.imap_unordered(lambda x:also_arg(factorial)(x), \n",
    "                              xrange(-1,MAX_SEGMENTS),\n",
    "                              CHUNK_SIZE)\n",
    "\n",
    "results = []\n",
    "                             \n",
    "for (i, result) in enumerate(islice(results_iter,None)):\n",
    "    print ('\\r>> Result %d' % i, end=\"\")\n",
    "    results.append(result)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "[f for f in islice(df.preferred_text_url,10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# http://chriskiehl.com/article/parallelism-in-one-line/\n",
    "from __future__ import print_function\n",
    "from multiprocessing import Pool as ProcessPool\n",
    "from multiprocessing.dummy import Pool as ThreadPool \n",
    "from functools import partial\n",
    "from itertools import islice\n",
    "\n",
    "from math import factorial\n",
    "\n",
    "# http://stackoverflow.com/questions/2348317/how-to-write-a-pager-for-python-iterators/2350904#2350904        \n",
    "def grouper(iterable, page_size):\n",
    "    page= []\n",
    "    for item in iterable:\n",
    "        page.append( item )\n",
    "        if len(page) == page_size:\n",
    "            yield page\n",
    "            page= []\n",
    "    if len(page) > 0:\n",
    "        yield page\n",
    "\n",
    "\n",
    "#get_key_sizes_for_bucket = partial(get_key_sizes, bucket_name=\"aws-publicdatasets\")\n",
    "\n",
    "PAGE_SIZE = 10\n",
    "POOL_SIZE = 8\n",
    "MAX_SEGMENTS = 20 # replace with None for all segments\n",
    "CHUNK_SIZE = 10\n",
    "\n",
    "pool = ThreadPool(POOL_SIZE)  # or ThreadPool\n",
    "results_iter = pool.imap_unordered(lambda x:also_arg(http_head_status)(x), \n",
    "                              islice(df.preferred_text_url, MAX_SEGMENTS),\n",
    "                              CHUNK_SIZE)\n",
    "\n",
    "results = []\n",
    "                             \n",
    "for (i, result) in enumerate(islice(results_iter,None)):\n",
    "    print ('\\r>> Result %d' % i, end=\"\")\n",
    "    results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wiki = TextBlob(\"Python is a high-level, general-purpose programming language.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wiki.noun_phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# alternative way to get Gutenberg texts\n",
    "# calculate the URI\n",
    "# https://github.com/c-w/Gutenberg/blob/PyPI-0.4/gutenberg/acquire/text.py#L19\n",
    "\n",
    "from gutenberg import acquire\n",
    "acquire.text._format_download_uri(2701)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
